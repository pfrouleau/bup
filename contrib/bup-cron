#! /usr/bin/python
# -*- coding: utf-8
"""Copyrights: Antoine BeauprÃ© from http://src.anarc.at/scripts.git/"""

"""
simple wrapper around bup index and save designed to be ran in cron
jobs, with support for filesystem snapshots, logging and configuration
files.
"""

"""
limitations
 * assumes POSIX
 * should be unit tested, at this point it's grown too big
 * no syslog support, because we would then need to use pipes to talk
   to bup, which would bring "interesting" results, loose
   interactivity (unless we use select(), which seems overkill), and
   complicate everything
 * no command-line parameters for many job's features
 * see XXX below for more

features missing
 * --test to run compare-tree after backup
 * support for BTRFS, ZFS, etc
"""

import argparse
import datetime
import errno
import json
import os
import re
import socket
import stat
import subprocess
import sys
import time
import traceback


class ArgumentConfigParser(argparse.ArgumentParser):
    configs = ['/etc/bup-cron.conf', '~/.bup-cron.conf', '~/.config/bup-cron.conf']
    snapshot_names = ['lvm', 'no']
    epilog = """options can also be specified, without --, in %s. an
    arbitrary configuration file may also be supplied on the
    commandline with a @ prefix (e.g. @foo.conf).

    at least path and repo need to be specified.
"""
    description = __doc__
    pidfile = 'bup-cron.pid'

    def __init__(self):
        if sys.platform.startswith('cygwin'):
            self.snapshot_names += ['vss']

        """various settings for the argument parser"""
        argparse.ArgumentParser.__init__(self,
                                         description=self.description,
                                         epilog=self.epilog %
                                         " or ".join(self.configs),
                                         fromfile_prefix_chars='@')
        self.add_argument('-v', '--verbose', action='count',
                          help="""output more information on console.
tries to be silent if not specified.
-v implies explaining what we do,
-vv shows output of commands,
-vvv passes verbose to those commands""")
        self.add_argument('-D', '--debug', action='store_true',
                          help="""print debug backtrace on unhandled exceptions
                                  - by default only the message is printed""")
        # using the hostname as branch name
        self.add_argument('-n', '--name', default=socket.gethostname(),
                          help="""name of the backup passed to bup,
                                  defaults to hostname (%(default)s)""")
        self.add_argument('-l', '--logfile', default=sys.stdout,
                          type=SaferFileType(mode='a', bufsize=1),
                          help="""file where logs should be written,
                                  defaults to stdout""")
        self.add_argument('--pidfile', default=None, action='store',
                          help="""lockfile to write to avoid
                                  simultanous execution, defaults to
                                  /var/run/%s"""
                          % self.pidfile)
        self.add_argument('-s', '--snapshot', nargs='?', default='no',
                          const='lvm', choices=self.snapshot_names,
                          help="""snapshot filesystem before backup.
                                  this will automatically guess the
                                  path to the logical volume, create a
                                  snapshot, mount it, then remove it
                                  when it is done, default: %(default)s""")
        self.add_argument('-z', '--size', action='store',
                          default=LvmSnapshot.size,
                          help="""size of the LVM snapshot,
                                  defaults to %(default)s""")
        self.add_argument('-m', '--mountpoint', action='store',
                          default=Snapshot.mountpattern,
                          help="""mountpoint of the snapshot device.
                                  should contain two %%s patterns, for
                                  the VG and LV names, default:
                                  %(default)s)""")
        self.add_argument('--clear', action='store_true',
                          help="""redo a full backup
                                  (runs bup index --clear before starting)""")
        self.add_argument('-x', '--exclude', action='append',
                          help="""exclude regex pattern,
                                  will be passed as --exclude-rx to bup""")
        self.add_argument('--parity', action='store_true',
                          help="""generate recovery blocks after backup.
                                  runs bup fsck -g after the backup,
                                  requires par2(1).""")
        self.add_argument('--jobfile', action='store', default=None,
                          help="""json file specifying the job to do""")
        if 'BUP_DIR' in os.environ:
            defdir = os.environ['BUP_DIR']
        else:
            defdir = None
        self.add_argument('-d', '--repository', default=defdir,
                          help="""the directory to backup to, defaults
                                  to $BUP_DIR (%s)"""
                          % defdir)
        # different list because dest=paths doesn't work, it gets
        # overwritten by the next one
        self.add_argument('-p', '--path', action='append',
                          help="""add path to list of paths to backup,
                                  mostly useful for the configuration file""")
        self.add_argument('paths', nargs='*', help='list of paths to backup')

    def convert_arg_line_to_args(self, arg_line):
        """parse a config file"""
        # skip whitespace and commented lines
        if re.match('^(#|[\s]*$)', arg_line):
            return []
        else:
            # all lines are assumed to be options
            return ['--' + arg_line]

    def parse_args(self):
        """process argument list

        inject system and user config files and cleanup various
        arguments and defaults that couldn't be done otherwise"""
        configs = map(lambda x: os.path.expanduser(x), self.configs)
        for conf in configs:
            try:
                with open(conf, 'r'):
                    sys.argv.insert(1, '@' + conf)
            except IOError:
                pass
        args = argparse.ArgumentParser.parse_args(self)
        if args.pidfile is None:
            args.pidfile = os.path.join('/var/run/', self.pidfile)
        # merge the path and paths arguments
        if args.path:
            args.paths += args.path
        # remove this one to avoid ambiguity
        del args.path
        if len(args.paths) > 0:
            args.jobs = [self.build_job(args)]
        elif args.jobfile:
            args.jobs = json.load(open(args.jobfile), object_hook=JsonBase.load_hook)
        else:
            self.error('argument paths or jobfile is required')
        return args

    def build_job(self, args):
        """Build the job instance out of the command line parameters

        Since the paths must be the file system mount point, put one
        path per target"""
        job = Job()
        job.job_name = "ad-hoc"

        if args.repository:
            local_rep = args.repository
            del args.repository # remove it to avoid ambiguity
        else:
            local_rep = os.environ['BUP_DIR']

        for path in args.paths:
            repo = Repo()
            repo.local_rep = local_rep
            repo.branch = args.name
            repo.includes = [path]

            target = Target()
            target.snapshot_type = args.snapshot
            target.snapshot_size = args.size
            target.mountpoint = args.mountpoint

            target.repos += [repo]
            job.targets += [target]

        return job


class SaferFileType(argparse.FileType):
    """Factory for creating file object types

    This replacement is necessary for two reasons:

    * '-' and mode='a' conflict
    * crashes if logfile cannot be opened, which breaks usage
    """
    def __call__(self, string):
        """override parent to get the behavior we want"""
        if string == '-' and 'a' in self._mode:
            self._mode = self._mode.replace('a', 'w')
        try:
            return argparse.FileType.__call__(self, string)
        except argparse.ArgumentTypeError as e:
            sys.stderr.write(str(e) + "\n")
            return sys.stdout


class Snapshot(object):
    """abstract class to handle filesystem snapshots"""

    """default location the snapshot is mounted on"""
    mountpattern = '/media/bup/%s-%s'

    def __init__(self, path, size, mountpattern=None,
                 log=sys.stdout.write, warn=sys.stderr.write,
                 verbose=0, call=subprocess.check_call):
        """initialise the snapshot array

        path is expected to be part of the target filesystem; log and warn are
        logging utilities; call is a way to call processes that will return
        true on success or false otherwise"""
        self.src_path = path
        self.path = path
        self.size = size
        self.log = log
        self.warn = warn
        self.verbose = verbose
        self.call = call
        # if the snapshot has been created
        self.exists = False
        if mountpattern is not None:
            self.mountpattern = mountpattern

    def __enter__(self):
        """this should be reimplemented by subclasses

        this should:

        1. create a snapshot
        2. mount it in a specific location
        3. set that location in self.path, or leave the original path
        in place otherwise"""
        return self

    def __exit__(self, t, e, tb):
        # return false to raise, true to pass
        self.cleanup()
        self.exists = False
        return t is None

    def cleanup(self):
        """this function should undo all that __enter__() did"""
        pass

    @staticmethod
    def select(name):
        """Returns the class who handles name"""
        for cls in Snapshot.__subclasses__():
            if name.lower() in cls.__name__.lower():
                return cls
        raise TypeError("Unknown type: %s" % name)

    def rebase(self, paths):
        """rebase the origin paths to the mounted location"""
        return [p.replace(self.src_path, self.path) for p in paths]


class NoSnapshot(Snapshot):
    """special class to skip snapshotting

    basically a noop"""
    pass


class LvmSnapshot(Snapshot):
    """Handle LVM snapshot"""

    """default snapshot size"""
    size = '1GB'

    def __enter__(self):
        """set the LVM and mount it"""
        self.vg_lv = None
        device, fs_root = self.find_device()
        if device:
            self.src_path = fs_root
            self.path = fs_root
            # vg, lv
            self.vg_lv = LvmSnapshot.find_vg_lv(device)
        if device and self.vg_lv:
            # forced cleanup
            self.cleanup(True)
            cmd = ['lvcreate', '--size', self.size, '--snapshot',
                   '--name', self.snapname(), device]
            if self.verbose <= 0:
                cmd += ['--quiet']
            if self.verbose >= 3:
                cmd += ['--verbose']
            if self.call(cmd):
                if make_dirs_helper(self.mountpoint()):
                    self.log('mountpoint %s created'
                             % self.mountpoint())
                self.exists = True
                if self.call(['mount', self.device(),
                              self.mountpoint()]):
                    self.path = self.mountpoint()
                else:
                    self.warn("""failed to mount snapshot %s on %s,
skipping snapshotting"""
                              % (self.snapname(),
                                 self.mountpoint()))
                    self.cleanup()
            else:
                self.warn("""failed to create snapshot %s/%s,
skipping snapshooting"""
                          % self.vg_lv)
        else:
            # XXX: we could try to find the parent mountpoint...
            self.warn('%s is not a LVM mountpoint, skipping snapshotting'
                      % self.path)
        return self

    def find_device(self):
        """find device based on mountpoint path

        returns the device or False if none found"""

        try:
            lastline = subprocess.check_output(['df', '-P', self.path]).splitlines()[-1]
            parts = lastline.split()
            return (parts[0], parts[-1])
        except:
            return (False, None)

    @staticmethod
    def find_vg_lv(device):
        """find the volume group and logical volume of the specified device"""
        try:
            lvs = subprocess.check_output(['lvs', device], close_fds=True)
        except subprocess.CalledProcessError:
            # not a LVM
            return False
        # second line of output, second and third fields, backwards
        return tuple(re.split(r' +', re.split("\n", lvs)[1])[2:0:-1])

    def snapname(self):
        """the name of the snapshot volume to be created

        pattern should have two string wildcards, one for vg, the
        other for lv"""
        return 'snap%s' % self.vg_lv[1]

    def mountpoint(self):
        """where to mount the snapshot device"""
        return self.mountpattern % self.vg_lv

    def device(self):
        """path to the device of the snapshot LV"""
        return '/dev/%s/%s' % (self.vg_lv[0], self.snapname())

    def cleanup(self, force=False):
        """cleanup everything we did here"""
        if not self.exists and not force:
            return
        self.exists = False
        m = self.mountpoint()
        # wait for bup to finish
        try:
            os.wait()
        except OSError as e:
            if e.errno == errno.ECHILD:  # no child process
                pass
            else:
                raise
        if os.path.ismount(m):
            if self.call(['umount', m]):
                self.log('umounted %s' % m)
            else:
                self.warn('failed to umount %s' % m)
        try:
            os.removedirs(m)
            self.log('removed directory %s' % m)
        except:
            pass
        device = self.device()
        try:
            # --force is required to avoid confirmation
            cmd = ['lvremove', '--force', device]
            if self.verbose <= 0:
                cmd += ['--quiet']
            if self.verbose >= 3:
                cmd += ['--verbose']
            if stat.S_ISBLK(os.stat(device).st_mode):
                if self.call(cmd):
                    self.log('dropped snapshot %s' % device)
                else:
                    self.warn('failed to drop snapshot %s' % device)
        except OSError:
            # normal: the device doesn't exist, moving on
            return


if sys.platform.startswith('cygwin'):
    class VssSnapshot(Snapshot):
        """Handle VSS snapshot, under Cygwin"""

        shadow_id = None
        winpath = None

        def __enter__(self):
            if ' ' in self.mountpattern:
                raise ValueError("mountpattern cannot contain a space")
            device, fs_root = self.find_device()
            if self.create_snapshot(device):
                self.mount(fs_root)
            else:
                self.warn("""failed to create snapshot for %s, skipping snapshotting""" %
                          self.path)
            return self

        def cleanup(self, force=False):
            if self.shadow_id is not None:
                device = self._convert2dos(self.src_path)
                self.log('dropping snapshot on %s' % device)
                if self.call(['vshadow', '-ds=%s' % self.shadow_id]):
                    self.shadow_id = None
                    self.exits = False
                    self.log('dropped snapshot %s' % device)
                else:
                    self.warn('failed to drop snapshot %s' % device)
            if os.path.exists(self.mountpattern):
                self._fail_if_mounted()
                os.rmdir(self.mountpattern)
                self.log('removed directory %s' % self.mountpattern)

        def _convert_path(self, path, spec):
            return subprocess.check_output(['cygpath', spec, path]).replace('\n','')

        def _convert2dos(self, linux_path):
            return self._convert_path(linux_path, '-aw')

        def _convert2linux(self, dos_path):
            return self._convert_path(dos_path, '-a').rstrip('/')

        def create_snapshot(self, device):
            self.cleanup(True)
            try:
                self.log('creating snapshot on %s' % device)
                # Note: Windows XP does not supports permanent shadows (-p)
                output = subprocess.check_output(['vshadow', '-p', device])
                #* SNAPSHOT ID = {5a698842-f325-404a-83e7-6a7fa08760a1}
                self.shadow_id = re.search("\* SNAPSHOT ID = (\{[0-9A-Fa-f-]{36}\})", output).group(1)
                self.log('Shadow copy created: %s' % self.shadow_id)
                self.src_path = self._convert2linux(device)
                self.exists = True
                return True
            except:
                self.warn('vss snapshot failed, id=%s' % self.shadow_id)
                return False

        def _fail_if_mounted(self):
            """throw if the mount point is already used

            The only way to unmount a mounted shadow copy is to erase it, so leave that
            decision to the user."""
            output = subprocess.check_output(['vshadow', '-q'])
            winmount = self._convert2dos(self.mountpattern).replace('\\','\\\\')
            mounted = re.search("^   - Exposed locally as: (%s)." % winmount,
                                output, re.MULTILINE | re.IGNORECASE)
            if mounted is not None:
                raise AlreadyMountedException(winmount)

        def find_device(self):
            # XXX: handle devices that are mounted through a directory.
            self.winpath = self._convert2dos(self.path)
            device = self.winpath[0:2]
            return (device, self._convert2linux(device))

        def mount(self, fs_root):
            """mountpattern must be a path in linux format
            """
            if make_dirs_helper(self.mountpattern):
                self.log('mountpoint %s created' % self.mountpattern)
            winmount = self._convert2dos(self.mountpattern)
            if len(winmount) == 3: # if it is a drive letter,
                winmount = winmount[:-1] # remove the trailing backslash
            if self.call(['vshadow', "-el=%s,%s" % (self.shadow_id, winmount)]):
                self.path = self.path.replace(fs_root, self.mountpattern)
            else:
                self.warn("""failed to mount snapshot %s on %s, skipping snapshotting""" %
                          (self.shadow_id, self.mountpattern))
                self.cleanup(True)


class JsonBase(object):
    """Base class for the json capable classes"""

    @staticmethod
    def can_load(dict):
        """Returns True if the dict contains a description of the class.

        Subclasses must redefine it"""
        raise NotImplementedError()

    @staticmethod
    def load_json(dict):
        """Create a class instance and initialize it from dict.

        Subclasses must redefine it"""
        raise NotImplementedError()

    @staticmethod
    def load_hook(dict):
        """hook to be use with json.load()"""

        for cls in JsonBase.__subclasses__():
            if cls.can_load(dict):
                return cls.load_json(dict)
        raise TypeError("Unknown node type")

    @staticmethod
    def dump_hook(obj):
        """hook to be use with json.dumps()"""

        if (isinstance(obj, JsonBase)):
            return obj.__dict__
        raise TypeError("Unknown type received: %s" % type(obj))


class Repo(JsonBase):
    """A repository in which some directories must be saved in a single branch"""

    local_rep = None
    remote_rep = None
    branch = None
    graft = False
    parity = False
    one_file_system = True
    includes = []
    excludes = []
    excludes_rx = []

    @staticmethod
    def can_load(dict):
        return 'local_rep' in dict

    @staticmethod
    def load_json(dict):
        o = Repo()
        o.local_rep = dict['local_rep']
        o.includes = dict['includes']
        if 'remote_rep' in dict: o.remote_rep = dict['remote_rep']
        if 'branch' in dict: o.branch = dict['branch']
        if 'graft' in dict: o.graft = dict['graft']
        if 'parity' in dict: o.parity = dict['parity']
        if 'one_file_system' in dict: o.parity = dict['one_file_system']
        if 'excludes' in dict: o.excludes = dict['excludes']
        if 'excludes_rx' in dict: o.excludes_rx = dict['excludes_rx']
        return o


class Target(JsonBase):
    """A target snapshot from which one or more directories must be saved

    The target is composed of one or more repos. This allow to create one
    snapshot and use it to backup in various repos."""

    snapshot_type = "no"
    snapshot_size = None
    mountpoint = None
    continue_without = True
    repos = []

    @staticmethod
    def can_load(dict):
        return 'repos' in dict

    @staticmethod
    def load_json(dict):
        o = Target()
        o.repos = dict['repos']
        if 'snapshot_type' in dict: o.snapshot_type = dict['snapshot_type']
        if 'snapshot_size' in dict: o.snapshot_size = dict['snapshot_size']
        if 'mountpoint' in dict: o.mountpoint = dict['mountpoint'].rstrip('/')
        if 'continue_without' in dict: o.continue_without = dict['continue_without']
        return o

    def common_prefix(self):
        includes = []
        for r in self.repos:
            includes += r.includes
        prefix = os.path.commonprefix(includes)
        # with includes=['/p/a32','/p/a64']
        # prefix = '/p/a', but we need '/p/'
        if prefix[-1] != '/':
            prefix = os.path.dirname(prefix)
        return prefix


class Job(JsonBase):
    """A backup job

    A job can be run at a scheduled time. It is composed of one or more targets.

    The overall structure is like this:
    {
        "job_name":"job 1",
        "log_modifications":[true|false],
        "targets":[{
            "snapshot_type":"snapshot_tech",
            "snapshot_size":"size",
            "mountpoint":"/absolute/path",
            "continue_without":[true|false],
            "repos":[{
                "local_rep":"/absolute/path/local.bup",
                "remote_rep":"bup@address:repos/repo.bup",
                "branch":"branch_pattern",
                "graft":[true|false],
                "parity":[true|false],
                "one_file_system":[true|false],
                "includes":[
                    "/absolute/path/dir/1",
                    "/absolute/path/dir/2",
                    "/absolute/path/dir/3"
                    ],
                "excludes":[
                    "/absolute/path/exc/1",
                    "/absolute/path/exc/2",
                    "/absolute/path/exc/3"
                    ],
                "excludes_rx":[
                    "python-regex-1",
                    "python-regex-2"
                    ]
                }]
            }]
    }"""

    job_name = None
    log_modifications = False
    targets = []

    @staticmethod
    def can_load(dict):
        return 'targets' in dict

    @staticmethod
    def load_json(dict):
        o = Job()
        o.job_name = dict['job_name']
        if 'log_modifications' in dict: o.log_modifications = dict['log_modifications']
        o.targets = dict['targets']
        return o


class Pidfile():
    """this class is designed to be used with the "with" construct

    it will create an exclusive lockfile, detect existing ones and
    remove stale files (with invalid pids or that the process
    disappeared)

    it will also cleanup after itself"""

    def __init__(self, path):
        """setup various parameters"""
        self.pidfile = path

    def __enter__(self):
        """wrapper around create() to work with the 'with' statement"""
        return self.create()

    def __exit__(self, t, e, tb):
        """remove the pid file, unless we detected another process"""
        # return false to raise, true to pass
        if t is None:
            # normal condition, no exception
            self.remove()
            return True
        elif t is ProcessRunningException:
            # do not remove the other process lockfile
            return False
        else:
            # other exception
            if self.pidfd:
                # this was our lockfile, removing
                self.remove()
            return False

    def create(self):
        """initialise pid file"""
        try:
            self.pidfd = os.open(self.pidfile,
                                 os.O_CREAT | os.O_WRONLY | os.O_EXCL)
            GlobalLogger().log('locked pidfile %s' % self.pidfile)
        except OSError as e:
            if e.errno == errno.EEXIST:
                pid = self._check()
                if pid:
                    self.pidfd = None
                    raise ProcessRunningException(self.pidfile, pid)
                else:
                    try:
                        os.remove(self.pidfile)
                        GlobalLogger().warn('removed staled lockfile %s'
                                            % (self.pidfile))
                        self.pidfd = os.open(self.pidfile,
                                             os.O_CREAT
                                             | os.O_WRONLY
                                             | os.O_EXCL)
                    except OSError as e:
                        if e.errno == errno.EACCES:
                            # we can't write to the file, most likely
                            # we weren't able to deliver the signal
                            # because it's running as a different user
                            # play it safe and abort
                            with open(self.pidfile, 'r') as f:
                                raise ProcessRunningException(self.pidfile,
                                                              f.read())
            else:
                raise

        os.write(self.pidfd, str(os.getpid()))
        os.close(self.pidfd)
        return self

    def remove(self):
        """helper function to actually remove the pid file"""
        GlobalLogger().log('removed pidfile %s' % self.pidfile)
        os.remove(self.pidfile)

    def _check(self):
        """check if a process is still running

        the process id is expected to be in pidfile, which should
        exist.

        if it is still running, returns the pid, if not, return
        False.

        this assumes we have privileges to send a signal to that
        process, but if we can't we're likely to be unable to
        overwrite the pidfile anyways."""
        with open(self.pidfile, 'r') as f:
            try:
                pidstr = f.read()
                pid = int(pidstr)
            except ValueError:
                # not an integer
                GlobalLogger().log("not an integer: %s" % pidstr)
                return False
            try:
                os.kill(pid, 0)
            except OSError:
                GlobalLogger().log("can't deliver signal to %s" % pid)
                return False
            else:
                return pid


class AlreadyMountedException(Exception):
    def __init__(self, path):
        """override parent constructor to keep path"""
        self.path = path
        return Exception.__init__(self,
                                  """
A snapshot is already mounted at that location:
  %s
Use "vshadow -q | grep -iB9 '%s'" to identify it and
use "vshadow -ds={SNAPSHOT_ID}" to unmount it and *erase* it."""
                                  % (path, path))


class ProcessRunningException(Exception):
    """an exception yielded by the Pidfile class when a process is
    detected using the pid file"""

    def __init__(self, path, pid):
        """override parent constructor to keep path and pid"""
        self.path = path
        self.pid = pid
        return Exception.__init__(self,
                                  'process already running in %s as pid %s'
                                  % (path, pid))


class Singleton(object):
    """singleton implementation

    inspired from:

   http://stackoverflow.com/questions/42558/python-and-the-singleton-pattern"""

    """the single object this will always return"""
    _instance = None

    """if __init__ was ran"""
    _init = False

    def __new__(cls, *args, **kwargs):
        """override constructor to return a single object"""
        if not cls._instance:
            cls._instance = super(Singleton, cls).__new__(
                cls, *args, **kwargs)
        return cls._instance

    def __init__(self, *args, **kwargs):
        """return if __init__ was previously ran"""
        super(Singleton, self).__init__(self, *args, **kwargs)
        i = self._init
        self._init = True
        return i


class GlobalLogger(Singleton):
    """logger

    this allows logging and warning (to stdout and stderr or a
    provided file object), with various verbosity levels.

    it also has a convenient executer with support for logging as
    well.

    XXX: this duplicates the builtin logging module."""

    def __init__(self, verbose=0, log=sys.stdout, warn=sys.stderr):
        """initialise the singleton, only if never initialised"""
        if not Singleton.__init__(self):
            self.verbose = verbose
            self._log = log
            self._warn = warn

    @staticmethod
    def logfmt(msg):
        """helper function to prepend time to messages"""
        return "%s %s\n" % (time.ctime(), msg)

    def log(self, msg, level=1):
        """log message to stdout or logfile, depending on --log"""
        if self.verbose >= level:
            self._log.write(GlobalLogger.logfmt(msg))

    def warn(self, msg):
        """log a warning to stderr and the logfile"""
        # if log is a file, copy there, otherwise stderr is enough
        if not self._log.isatty():
            self.log(msg, 0)
        self._warn.write(GlobalLogger.logfmt(msg))

    def check_call(self, cmd):
        """call a procss, log it to the logfile

        return false if it fails, otherwise true"""
        try:
            self.log('calling command `%s`' % " ".join(cmd), 2)
            if self.verbose >= 2:
                stdout = self._log
            else:
                stdout = file(os.devnull)
            subprocess.check_call(cmd, stdout=stdout, stderr=self._warn,
                                  close_fds=True)
        except subprocess.CalledProcessError:
            self.warn('command failed')
            return False
        return True

    def check_call_piped(self, cmd1, r1, cmd2, r2):
        """call a procss, log it to the logfile

        return false if it fails, otherwise true"""
        result = True
        p1r = p2r = None
        try:
            # XXX: why is the level is not seen as a level?
            self.log('calling commands `%s` | `%s`' % (' '.join(cmd1), ' '.join(cmd2)), 2)
            p1 = subprocess.Popen(cmd1, close_fds=True, stderr=self._warn, stdout=subprocess.PIPE)
            p2 = subprocess.Popen(cmd2, close_fds=True, stderr=self._warn, stdout=self._log, stdin=p1.stdout)
            p1.stdout.close()
            p2r = p2.wait()
            p1r = p1.wait()
            if p1r > r1 or p2r > r2:
                self.warn('pipe failed (%s,%s)' % (p1r, p2r))
                result = False
        except subprocess.CalledProcessError:
            self.warn('pipe failed')
            result = False
        return [result, p1r, p2r]


class Timer(object):
    """this class is to track time and resources passed"""

    def __init__(self):
        """initialize the timstamp"""
        self.stamp = datetime.datetime.now()

    def times(self):
        """return a string designing resource usage"""
        return 'user %s system %s chlduser %s chldsystem %s' % os.times()[:4]

    def diff(self):
        """a datediff between the creation of the object and now"""
        return datetime.datetime.now() - self.stamp

    def __str__(self):
        """return a string representing the time passed and resources used"""
        return 'elasped: %s (%s)' % (str(self.diff()), self.times())


def make_dirs_helper(path):
    """Create the directory if it does not exist

    Return True if the directory was created, false if it was already
    present, throw an OSError exception if it cannot be created"""
    try:
        os.makedirs(path)
        return True
    except OSError as ex:
        if ex.errno != errno.EEXIST or not os.path.isdir(path):
            raise
        return False


def update_index(repo, snapshot):
    success = True
    for path in snapshot.rebase(repo.includes):
        # XXX: this shouldn't be in the loop like this, bup index should be
        # able to index multiple paths
        #
        # unfortunately, `bup index --one-file-system / /var` skips /var...
        GlobalLogger().log('indexing %s' % path)
        # XXX: should be -q(uiet) unless verbose > 0 - but bup
        # index has no -q
        cmd = ['bup', 'index']
        if GlobalLogger().verbose >= 4:
            cmd += ['--verbose']
        if repo.excludes:
           cmd += map((lambda ex: '--exclude=' + ex), snapshot.rebase(repo.excludes))
        if repo.excludes_rx:
            cmd += map((lambda ex: '--exclude-rx=' + ex), repo.excludes_rx)
        if repo.one_file_system:
            cmd += ['--one-file-system']
        cmd += [path]
        success &= GlobalLogger().check_call(cmd)
    return success


def list_modifications(repo, snapshot):
    GlobalLogger().log('Looking for new or modified files:')
    cmd1 = ['bup', 'index', '-sm'] + snapshot.rebase(repo.includes)
    cmd2 = ['grep', '-v', r'/\$']
    success, _, r2 = GlobalLogger().check_call_piped(cmd1, 0, cmd2, 1)
    if r2 == 1:
        GlobalLogger().log('Nothing is new or was modified')
        # Note:
        # The log says nothing about deleted files... bup index does not list them,
        # and even if it was, the deleted files always stays in the index and would
        # always be listed.
        # Because of this, we cannot skip the save step.
    return success


def save_data(repo, snapshot):
    GlobalLogger().log('saving %s' % snapshot.path)
    cmd = ['bup', 'save']
    if GlobalLogger().verbose <= 0:
        cmd += ['--quiet']
    elif GlobalLogger().verbose >= 3:
        cmd += ['--verbose']
    if repo.remote_rep:
        cmd += ['-r', repo.remote_rep]
    if repo.graft and snapshot.exists:
        cmd += ['--name', repo.branch]
        cmd += ['--graft', '%s=%s' % (snapshot.path, snapshot.src_path)]
    else:
        # we strip the path, so it's cleaner to include it in the name
        cmd += ['--name', repo.branch + '-' + snapshot.src_path.replace('/', '_')]
        cmd += ['--strip-path', snapshot.path]
    #  -t and -c are apparently useful in case of disaster;
    # unfortunately, they are useless if we don't show or log the output
    if GlobalLogger().verbose >= 2:
        cmd += ['--tree', '--commit']
    cmd += snapshot.rebase(repo.includes)
    GlobalLogger().check_call(cmd)


def generate_par2(repo):
    base_cmd = ['bup', 'fsck']
    if repo.remote_rep:
        # XXX: maybe bup-fsck could learn to work on remote repository
        addr, path = repo.remote_rep.split(':')
        base_cmd = ['ssh', addr, 'bup', '-d', path, 'fsck']

    cmd = base_cmd + ['--par2-ok']
    if GlobalLogger().check_call(cmd):
        cmd = base_cmd
        cmd += ['--generate']
        if GlobalLogger().verbose >= 3:
            cmd += ['--verbose']
        GlobalLogger().log('generating par2(1) recovery blocks')
        GlobalLogger().check_call(cmd)
    else:
        GlobalLogger().warn("""bup reports par2(1) as not working,
no recovery blocks written""")


def process_repo(args, repo, snapshot):
    os.environ['BUP_DIR'] = repo.local_rep
    if make_dirs_helper(repo.local_rep):
        GlobalLogger().log("initiating bup's dir %s" % repo.local_rep)
        cmd = ['bup', 'init']
        if repo.remote_rep:
            cmd += ['-r', repo.remote_rep]
        GlobalLogger().check_call(cmd)
    else:
        if args.clear:
            GlobalLogger().log('clearing the index')
            GlobalLogger().check_call(['bup', 'index', '--clear'])

    GlobalLogger().log('backing up %s to %s'
                       % (" ".join(repo.includes), repo.local_rep))
    if not update_index(repo, snapshot):
        GlobalLogger().warn('skipping save because index failed!')
        return

    if args.current_job.log_modifications:
        GlobalLogger().log('#---------------------------------------', 2)
        if not list_modifications(repo, snapshot):
            GlobalLogger().warn('skipping save because grep failed!')
            return

    GlobalLogger().log('#---------------------------------------', 2)
    save_data(repo, snapshot)

    if repo.parity:
        generate_par2(repo)
    GlobalLogger().log('#---------------------------------------', 2)


def process_target(args, target):
    # current lvm object to cleanup in exception handlers
    with Snapshot.select(target.snapshot_type)(target.common_prefix(),
                         target.snapshot_size, target.mountpoint,
                         GlobalLogger().log, GlobalLogger().warn,
                         GlobalLogger().verbose, GlobalLogger().check_call) as snapshot:
        if snapshot.exists or target.continue_without or 'no' == target.snapshot_type.lower():
            for repo in target.repos:
                process_repo(args, repo, snapshot)
        else:
            GlobalLogger().warn('skipping %s because snapshot failled'
                                % target.mountpoint)


def process(args):
    """main processing loop"""
    GlobalLogger().log('################################################', 1)
    job_count = len(args.jobs)
    for job in args.jobs:
        job_count -= 1
        timer = Timer()
        GlobalLogger().log('Starting job "%s"' % job.job_name)
        args.current_job = job
        for target in job.targets:
            process_target(args, target)
        GlobalLogger().log('Completed job "%s"' % job.job_name)
        if job_count > 0:
            GlobalLogger().log(str(timer))


def bail(status, timer, msg=None):
    """cleanup on exit"""
    if msg:
        GlobalLogger().warn(msg)
    GlobalLogger().log(str(timer))
    sys.exit(status)


def main():
    """main entry point, sets up error handlers and parses arguments"""

    args = ArgumentConfigParser().parse_args()
    timer = Timer()

    # initialize GlobalLogger singleton
    GlobalLogger(args.verbose, args.logfile)

    try:
        with Pidfile(args.pidfile):
            process(args)
    except:
        # get exception type and error, but print the traceback in debug
        t, e, b = sys.exc_info()
        GlobalLogger().warn('aborting with %s exception: %s' % (t.__name__, e))
        if args.debug:
            GlobalLogger().warn(traceback.print_tb(b))
        bail(1, timer)
    bail(0, timer)

if __name__ == '__main__':
    main()
